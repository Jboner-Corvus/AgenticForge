<p align="center">
  <img src="assets/title.png" alt="Agentic Forge Logo" width="250">
</p>

<h1 align="center">AgenticForge</h1>

<p align="center">
  <img src="https://img.shields.io/badge/üî®-Agentic_Forge-orange?style=for-the-badge" alt="Agentic Forge Logo">
</p>
<p align="center">
  <strong>üåê Langues disponibles</strong><br>
  <a href="README_EN.md">English</a> ‚Ä¢ 
  <a href="README.md">Fran√ßais</a> ‚Ä¢ 
  <a href="README_CHS.md">‰∏≠Êñá</a> ‚Ä¢ 
  <a href="README_CHT.md">ÁπÅÈ´î‰∏≠Êñá</a> ‚Ä¢ 
  <a href="README_JP.md">Êó•Êú¨Ë™û</a> ‚Ä¢ 
  <a href="README_PTBR.md">Portugu√™s (Brasil)</a> ‚Ä¢ 
  <a href="README_ES.md">Espa√±ol</a>
</p> 
<h3 align="center">
      Une alternative priv√©e et locale √† MANUS.
</h3>

<p align="center">
  <em>
    Un agent IA 100% autonome, gratuit et local qui forge ses propres outils, √©crit du code et ex√©cute des t√¢ches complexes, tout en conservant l'int√©gralit√© des donn√©es sur votre appareil. Bas√© sur le protocole MCP (Model Context Protocol) avec FastMCP comme moteur, il est con√ßu pour les mod√®les de raisonnement locaux et adaptable √† l'API de votre LLM favori, garantissant une confidentialit√© totale et aucune d√©pendance au cloud.
  </em>
</p>
<br>
<p align="center">
    <img src="https://img.shields.io/badge/License-MIT-green.svg?style=flat-square&logo=opensource&logoColor=white" alt="MIT License"> <img src="https://img.shields.io/github/stars/Jboner-Corvus/AgenticForge?style=flat-square&logo=github&color=gold" alt="Stars"> <img src="https://img.shields.io/github/forks/Jboner-Corvus/AgenticForge?style=flat-square&logo=git&color=blue" alt="Forks"> <img src="https://img.shields.io/github/issues/Jboner-Corvus/AgenticForge?style=flat-square&logo=github" alt="Issues">
</p>
<p align="center">
    <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker">
    <img src="https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white" alt="Node.js">
    <img src="https://img.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white" alt="TypeScript">
    <img src="https://img.shields.io/badge/Redis-DC382D?style=for-the-badge&logo=redis&logoColor=white" alt="Redis">
    <img src="https://img.shields.io/badge/MCP-000000?style=for-the-badge&logoColor=white" alt="MCP">
    <img src="https://img.shields.io/badge/pnpm-F69220?style=for-the-badge&logo=pnpm&logoColor=white" alt="pnpm">
</p>

## Pourquoi Agentic Forge ?

üîí **Enti√®rement Local et Priv√©** - Tout fonctionne sur votre machine ‚Äî pas de cloud, pas de partage de donn√©es. Vos fichiers, conversations et outils restent priv√©s.

üõ†Ô∏è **Auto-Forge d'Outils** - Agentic Forge peut cr√©er ses propres outils ‚Äî quand une capacit√© lui manque, il √©crit le code pour la construire.

üíª **Assistant de Codage Autonome** - Besoin de code ? Il peut √©crire, d√©boguer et ex√©cuter des programmes en Python, TypeScript, Bash et plus ‚Äî sans supervision.

üß† **S√©lection Intelligente d'Outils** - Vous demandez, il trouve automatiquement le meilleur outil pour le travail. Comme avoir une forge d'experts pr√™ts √† aider.

üìã **Planifie et Ex√©cute des T√¢ches Complexes** - De la gestion de fichiers au scraping web ‚Äî il peut diviser les grandes t√¢ches en √©tapes et forger les outils pour accomplir le travail.

üåê **Navigation Web Intelligente** - Agentic Forge peut naviguer sur internet de mani√®re autonome ‚Äî rechercher, lire, extraire des infos, automatiser des t√¢ches ‚Äî le tout sans intervention.

üöÄ **Propuls√© par FastMCP** - Utilise le protocole MCP (Model Context Protocol) avec FastMCP comme framework ultra-performant ‚Äî une v√©ritable fus√©e pour les interactions LLM.

---

## D√©mo

> **"Peux-tu cr√©er un outil pour analyser une une cotation boursiere pour en faire le trading?"**

---

## üõ†Ô∏è ‚ö†Ô∏è Travail Actif en Cours

üôè Ce projet a commenc√© pour prouver que MCP etait mieux que API et a grandi au-del√† des attentes. Les contributions, commentaires et patience sont profond√©ment appr√©ci√©s alors que nous forgeons de l'avant.

---

## Pr√©requis

Avant de commencer, assurez-vous d'avoir les logiciels suivants install√©s :

- **Git** : Pour cloner le d√©p√¥t. [T√©l√©charger Git](https://git-scm.com/)
- **Docker Engine & Docker Compose** : Pour ex√©cuter les services group√©s.
  - [Installer Docker Desktop](https://www.docker.com/products/docker-desktop/) (inclut Docker Compose V2) : Windows | Mac | Linux
  - Ou installer s√©par√©ment : [Docker Engine](https://docs.docker.com/engine/install/) | [Docker Compose](https://docs.docker.com/compose/install/)
- **Node.js 20+** : Pour l'interface web. [T√©l√©charger Node.js](https://nodejs.org/)
- **pnpm** : Gestionnaire de paquets. Installer avec `npm install -g pnpm`

---

## 1. Cloner le d√©p√¥t

```bash
git clone https://github.com/votre-username/agentic-forge.git
cd agentic-forge
```

## 2. Lancer le script de gestion

Rendez le script de gestion ex√©cutable (sur Linux/macOS) et lancez-le.

```bash
# Sur Linux ou macOS
chmod +x run.sh
./run.sh

# Sur Windows
./run.sh
```

√Ä la premi√®re ex√©cution, le script v√©rifiera si un fichier `.env` existe. S'il n'existe pas, il le cr√©era automatiquement pour vous avec les valeurs par d√©faut.

## 3. Configurer votre environnement

Ouvrez le fichier `.env` qui a √©t√© cr√©√© et remplissez les valeurs. Voici un exemple bas√© sur le fichier g√©n√©r√© automatiquement.

```env
# Fichier .env g√©n√©r√© automatiquement. Remplissez les valeurs.
# Port expos√© par le serveur principal
PUBLIC_PORT=8080
# Port de l'interface web
WEB_PORT=3002

# --- Configuration Redis ---
# Le worker local se connectera √† Redis via localhost sur ce port.
# Assurez-vous que ce port correspond √† celui expos√© dans docker-compose.yml.
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_HOST_PORT=6379
REDIS_PASSWORD=""

# --- Configuration du LLM et de l'Authentification ---
LLM_API_KEY="votre_cle_api_gemini"
LLM_MODEL_NAME=gemini-1.5-flash
AUTH_TOKEN="un_token_secret_et_long_de_votre_choix"

# --- Configuration Technique ---
NODE_ENV=development
LOG_LEVEL=info
```

**Important** :
- D√©finissez un `AUTH_TOKEN` fort (32+ caract√®res recommand√©s).
- Les cl√©s API sont optionnelles si vous utilisez des mod√®les locaux.

---

## 4. D√©marrer Docker

Assurez-vous que Docker est en cours d'ex√©cution avant de continuer.

---

## Configuration pour LLM Local (Recommand√©)

### Exigences Mat√©rielles

| Taille Mod√®le | M√©moire GPU | Performance                                |
| ------------- | ----------- | ------------------------------------------ |
| 7B            | 8GB VRAM    | ‚ö†Ô∏è T√¢ches basiques seulement               |
| 14B           | 12GB VRAM   | ‚úÖ La plupart des t√¢ches fonctionnent bien |
| 32B           | 24GB VRAM   | üöÄ Excellentes performances                |
| 70B+          | 48GB+ VRAM  | üí™ Qualit√© professionnelle                 |

### Configuration avec Ollama (Recommand√©)

1.  **Installer Ollama** : [T√©l√©charger Ollama](https://ollama.ai/)
2.  **D√©marrer Ollama** :
    ```bash
    ollama serve
    ```
3.  **T√©l√©charger un mod√®le de raisonnement** :
    ```bash
    ollama pull deepseek-r1:14b
    # ou pour plus de puissance : ollama pull deepseek-r1:32b
    ```
4.  **Mettre √† jour la configuration** dans `.env` :
    ```env
    LLM_MODEL_NAME="deepseek-r1:14b"
    LLM_API_BASE_URL="http://localhost:11434"
    ```

### Alternative : LM Studio

1.  T√©l√©chargez et installez [LM Studio](https://lmstudio.ai/)
2.  Chargez un mod√®le comme `deepseek-r1-distill-qwen-14b`
3.  D√©marrez le serveur local
4.  Mettez √† jour `.env` :
    ```env
    LLM_API_BASE_URL="http://localhost:1234"
    ```

---

## Configuration pour Usage API

Si vous pr√©f√©rez les mod√®les cloud ou manquez de mat√©riel suffisant :

### 1. Choisir un fournisseur d'API

| Fournisseur | Mod√®les Exemples                     | Lien Cl√© API                                              |
| ----------- | ------------------------------------ | --------------------------------------------------------- |
| OpenAI      | `gpt-4`, `o1`                        | [platform.openai.com](https://platform.openai.com/signup) |
| Google      | `gemini-2.5-pro`, `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com/keys)   |
| Anthropic   | `claude-4-sonnet`, `claude-4-opus`   | [console.anthropic.com](https://console.anthropic.com/)   |
| DeepSeek    | `deepseek-chat`, `deepseek-coder`    | [platform.deepseek.com](https://platform.deepseek.com)    |

### 2. D√©finir votre cl√© API

**Linux/macOS :**
```bash
export LLM_API_KEY="votre_cle_api_ici"
# Ajoutez √† ~/.bashrc ou ~/.zshrc pour la persistance
```

**Windows :**
```cmd
set LLM_API_KEY=votre_cle_api_ici
```

### 3. Mettre √† jour `.env` :
```env
LLM_API_KEY="votre_cle_api_ici"
LLM_MODEL_NAME="gemini-1.5-pro" # ou un autre mod√®le de votre choix
```

---

## D√©marrer les Services et Ex√©cuter

### Utiliser la Console de Gestion (`run.sh`)

Apr√®s avoir configur√© votre fichier `.env`, utilisez la console de gestion pour d√©marrer l'application.

Lancez la console interactive :
```bash
./run.sh
```

Depuis le menu de la console :
1.  **D√©marrer** - Lancer tous les services
2.  **Statut** - V√©rifier la sant√© des services
3.  **Logs** - Surveiller les logs en temps r√©el

### Commandes Docker Manuelles

D√©marrer tous les services :
```bash
docker compose up -d
```

V√©rifier le statut :
```bash
docker compose ps
```

Voir les logs :
```bash
docker compose logs -f
```

**‚ö†Ô∏è Attention** : Le d√©marrage initial peut prendre plusieurs minutes car les images Docker sont t√©l√©charg√©es et les services s'initialisent. Attendez de voir `agentic_forge_server | ... "GET /api/health HTTP/1.1" 200 ...` dans les logs.

---

## Points d'Acc√®s

Une fois les services en marche :

| Service                | URL                                                 | Description                      |
| ---------------------- | --------------------------------------------------- | -------------------------------- |
| **Interface Web**      | http://localhost:${WEB_PORT:-3002}                  | Interface utilisateur principale |
| **Point d'API**        | http://localhost:${PUBLIC_PORT:-8080}/api/v1/agent/stream | Acc√®s API direct                 |
| **V√©rification Sant√©** | http://localhost:${PUBLIC_PORT:-8080}/api/health    | Statut de sant√© des services     |

### Test Rapide

```bash
# V√©rification sant√©
curl http://localhost:8080/api/health

# Test API (remplacez VOTRE_AUTH_TOKEN)
curl -X POST http://localhost:8080/api/v1/agent/stream 
  -H "Content-Type: application/json" 
  -H "Authorization: Bearer VOTRE_AUTH_TOKEN" 
  -d '{"goal": "Cr√©e un simple script Python hello world"}'
```

---

## Exemples d'Usage

Une fois vos services en marche, essayez ces exemples :

### üîß Forge d'Outils
```
"J'ai besoin d'un outil pour convertir des fichiers CSV en format JSON. Cr√©e-le puis utilise-le sur mon fichier donnees.csv."
```

### üíª G√©n√©ration de Code
```
"√âcris un script Python qui surveille un r√©pertoire pour les nouveaux fichiers et enregistre leurs d√©tails."
```

### üåê Automatisation Web
```
"Recherche en ligne les derni√®res bonnes pratiques TypeScript et cr√©e un document de r√©sum√©."
```

### üìä Analyse de Donn√©es
```
"Analyse le fichier donnees_ventes.csv dans mon espace de travail et cr√©e une visualisation des tendances."
```

### üõ†Ô∏è T√¢ches Syst√®me
```
"Cr√©e un script de sauvegarde pour mes fichiers importants et programme son ex√©cution quotidienne."
```

**Note** : Soyez explicite dans vos demandes. Au lieu de "Est-ce que tu connais X ?", demandez "Recherche en ligne des informations sur X et r√©sume-les."

---

## Console de Gestion (`run.sh`)

La console interactive fournit un contr√¥le complet sur votre instance Agentic Forge :

```
   ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
   ‚ïë      A G E N T I C  F O R G E    ‚ïë
   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Docker & Services
   1) üü¢ D√©marrer         5) üìä Logs
   2) üîÑ Red√©marrer       6) üêö Shell (Container)
   3) üî¥ Arr√™ter          7) üî® Rebuild (no cache)
   4) ‚ö° Statut           8) üßπ Nettoyer Docker

  D√©veloppement
  10) üîç Lint           12) üß™ Tests
  11) ‚ú® Format         13) üìò TypeCheck

  16) üö™ Quitter
```

### Commandes Cl√©s

| Option | Description             | Quand l'Utiliser                   |
| ------ | ----------------------- | ---------------------------------- |
| **1**  | D√©marrer l'√©cosyst√®me   | Premier lancement ou apr√®s arr√™t   |
| **2**  | Red√©marrer les services | Apr√®s changements de configuration |
| **4**  | V√©rifier le statut      | Diagnostics de sant√©               |
| **5**  | Suivre les logs         | Surveillance en temps r√©el         |
| **7**  | Reconstruire les images | Apr√®s changements majeurs de code  |

---

## Aper√ßu de l'Architecture

### üèóÔ∏è Microservices Distribu√©s

- **üß† Serveur** (Port `${PUBLIC_PORT:-8080}`) : Orchestration centrale, communication LLM, gestion de session
- **‚ö° Worker** : Traitement de t√¢ches asynchrones, ex√©cution de code, automatisation web
- **üåê Interface Web** (Port `${WEB_PORT:-3002}`) : UI moderne bas√©e sur React
- **üíæ Redis** (Port `6379`) : File de t√¢ches, stockage de session, mise en cache

### üîÑ Processus de Forge d'Outils

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant S as Serveur
    participant L as LLM
    participant W as Worker
    participant F as Syst√®me Fichiers

    U->>S: "Cr√©e un outil d'analyse CSV"
    S->>L: G√©n√®re plan de cr√©ation d'outil
    L->>S: Code d'outil + sp√©cifications
    S->>F: √âcrit l'outil sur le syst√®me de fichiers
    S->>S: Auto-red√©marrage pour charger l'outil
    S->>W: Ex√©cute le nouvel outil
    W->>S: R√©sultats
    S->>U: Outil cr√©√© et ex√©cut√©
```

---

## D√©veloppement

### Structure du Projet

```
agentic-forge/
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ core/                  # Code source du Backend et du Worker
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ worker.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools/         # Outils disponibles
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts/       # Templates de prompts LLM
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/         # Utilitaires
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ ui/                    # Code source du Frontend
‚îÇ       ‚îú‚îÄ‚îÄ src/
‚îÇ       ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ .env                       # Fichier de configuration (local)
‚îú‚îÄ‚îÄ docker-compose.yml         # Orchestration des services
‚îú‚îÄ‚îÄ run.sh                     # Script de gestion
‚îî‚îÄ‚îÄ README_FR.md               # Cette documentation
```

### Ajouter des Outils Personnalis√©s

```typescript
// packages/core/src/tools/custom/monOutil.tool.ts
import { z } from 'zod';
import type { Tool, Ctx } from '../../types.js';

export const monOutilParams = z.object({
  entree: z.string().describe("Param√®tre d'entr√©e"),
  options: z.number().default(1),
});

export const monOutil: Tool<typeof monOutilParams> = {
  name: 'monOutilPersonnalise',
  description: 'Description de ce que fait cet outil',
  parameters: monOutilParams,
  execute: async (args, ctx: Ctx) => {
    ctx.log.info('Ex√©cution outil personnalis√©', { args });

    // Votre logique d'outil ici
    const resultat = await traiterEntree(args.entree, args.options);

    return resultat;
  },
};
```

N'oubliez pas de l'ajouter √† `packages/core/src/tools/index.ts` :

```typescript
import { monOutil } from './custom/monOutil.tool.js';

export const allTools: Tool<any>[] = [
  // ... outils existants
  monOutil,
];
```

---

## Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour les d√©tails.

---

## Remerciements

- **[FastMCP](https://github.com/punkpeye/fastmcp)** : Framework MCP ultra-performant - la fus√©e qui propulse Agentic Forge üöÄ
- **[Model Context Protocol (MCP)](https://modelcontextprotocol.io/)** : Protocole r√©volutionnaire pour l'interaction avec les LLMs
- **[Docker](https://docker.com)** : Conteneurisation et isolation
- **[Redis](https://redis.io)** : Structures de donn√©es haute performance
- **[Playwright](https://playwright.dev)** : Automatisation web moderne
- **Communaut√© Open Source** : Pour l'inspiration et la collaboration

---

## Support

- **Issues** : [GitHub Issues](https://github.com/votre-username/agentic-forge/issues)
- **Discussions** : [GitHub Discussions](https://github.com/votre-username/agentic-forge/discussions)
- **Documentation** : [Wiki du Projet](https://github.com/votre-username/agentic-forge/wiki)

---

<div align="center">

**üî® Un forgeron forge ses marteaux.** **ü§ñ Agentic Forge forge ses propres capacit√©s.**

_Forgez votre avenir technologique._

[![Commencer](https://img.shields.io/badge/üöÄ_Commencer-brightgreen?style=for-the-badge)](./run.sh)

</div>
